{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c95d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:27:40.896140Z",
     "iopub.status.busy": "2024-02-27T13:27:40.895755Z",
     "iopub.status.idle": "2024-02-27T13:27:43.766004Z",
     "shell.execute_reply": "2024-02-27T13:27:43.765075Z"
    },
    "executionInfo": {
     "elapsed": 4948,
     "status": "ok",
     "timestamp": 1709005841446,
     "user": {
      "displayName": "Ha Nguyen",
      "userId": "01126135657783667090"
     },
     "user_tz": -420
    },
    "id": "TqWnD3x1rtVT",
    "outputId": "d21f1912-c295-4a41-a9ff-583d589a305c",
    "papermill": {
     "duration": 2.880038,
     "end_time": "2024-02-27T13:27:43.768180",
     "exception": false,
     "start_time": "2024-02-27T13:27:40.888142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'yolov5'...\r\n",
      "remote: Enumerating objects: 16491, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (83/83), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (74/74), done.\u001b[K\r\n",
      "remote: Total 16491 (delta 27), reused 35 (delta 9), pack-reused 16408\u001b[K\r\n",
      "Receiving objects: 100% (16491/16491), 15.16 MiB | 21.03 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11287/11287), done.\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04e37dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:27:43.784743Z",
     "iopub.status.busy": "2024-02-27T13:27:43.784465Z",
     "iopub.status.idle": "2024-02-27T13:27:58.330568Z",
     "shell.execute_reply": "2024-02-27T13:27:58.329326Z"
    },
    "executionInfo": {
     "elapsed": 10030,
     "status": "ok",
     "timestamp": 1709005861203,
     "user": {
      "displayName": "Ha Nguyen",
      "userId": "01126135657783667090"
     },
     "user_tz": -420
    },
    "id": "Vbq5jKy3r48A",
    "outputId": "c8bd1275-9a0b-4f93-d087-00b1b0851dff",
    "papermill": {
     "duration": 14.556686,
     "end_time": "2024-02-27T13:27:58.332661",
     "exception": false,
     "start_time": "2024-02-27T13:27:43.775975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/yolov5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/yolov5\n",
    "%pip install -qr requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f12448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:27:58.349830Z",
     "iopub.status.busy": "2024-02-27T13:27:58.349409Z",
     "iopub.status.idle": "2024-02-27T13:28:11.331108Z",
     "shell.execute_reply": "2024-02-27T13:28:11.330115Z"
    },
    "executionInfo": {
     "elapsed": 10067,
     "status": "ok",
     "timestamp": 1709005975801,
     "user": {
      "displayName": "Ha Nguyen",
      "userId": "01126135657783667090"
     },
     "user_tz": -420
    },
    "id": "y-32Qub4r8g3",
    "outputId": "ec58ef86-8afb-4043-ab03-8a10f0c30251",
    "papermill": {
     "duration": 12.992694,
     "end_time": "2024-02-27T13:28:11.333208",
     "exception": false,
     "start_time": "2024-02-27T13:27:58.340514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (4 CPUs, 31.4 GB RAM, 5432.4/8062.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from yolov5 import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7713bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:28:11.350896Z",
     "iopub.status.busy": "2024-02-27T13:28:11.350023Z",
     "iopub.status.idle": "2024-02-27T13:28:11.354783Z",
     "shell.execute_reply": "2024-02-27T13:28:11.354002Z"
    },
    "executionInfo": {
     "elapsed": 9338,
     "status": "ok",
     "timestamp": 1709007640384,
     "user": {
      "displayName": "Ha Nguyen",
      "userId": "01126135657783667090"
     },
     "user_tz": -420
    },
    "id": "jlE8VEnPsYeP",
    "outputId": "6618df95-6e32-43f2-98cc-4570edaeaa84",
    "papermill": {
     "duration": 0.015314,
     "end_time": "2024-02-27T13:28:11.356556",
     "exception": false,
     "start_time": "2024-02-27T13:28:11.341242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79337fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:28:11.373415Z",
     "iopub.status.busy": "2024-02-27T13:28:11.373123Z",
     "iopub.status.idle": "2024-02-27T13:28:11.378290Z",
     "shell.execute_reply": "2024-02-27T13:28:11.377477Z"
    },
    "executionInfo": {
     "elapsed": 14140,
     "status": "ok",
     "timestamp": 1709007831029,
     "user": {
      "displayName": "Ha Nguyen",
      "userId": "01126135657783667090"
     },
     "user_tz": -420
    },
    "id": "FfAA5_2YyvCT",
    "outputId": "4b96197c-254d-470c-cbaf-d63725745252",
    "papermill": {
     "duration": 0.015737,
     "end_time": "2024-02-27T13:28:11.380150",
     "exception": false,
     "start_time": "2024-02-27T13:28:11.364413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DATAPATH\n",
    "test_path = \"/kaggle/input/Senior-Design-VIAD-4/test\"\n",
    "train_path = \"/kaggle/input/Senior-Design-VIAD-4/train\"\n",
    "valid_path = \"/kaggle/input/Senior-Design-VIAD-4/valid\"\n",
    "os.mkdir('/kaggle/working/yolov5/data/coco')\n",
    "os.mkdir('/kaggle/working/yolov5/data/coco/labels')\n",
    "os.mkdir('/kaggle/working/yolov5/data/coco/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0a84d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:28:11.396969Z",
     "iopub.status.busy": "2024-02-27T13:28:11.396686Z",
     "iopub.status.idle": "2024-02-27T13:28:11.400460Z",
     "shell.execute_reply": "2024-02-27T13:28:11.399717Z"
    },
    "papermill": {
     "duration": 0.01429,
     "end_time": "2024-02-27T13:28:11.402236",
     "exception": false,
     "start_time": "2024-02-27T13:28:11.387946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.listdir('/kaggle/input/Senior-Design-VIAD-4/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a213ef05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:28:11.419591Z",
     "iopub.status.busy": "2024-02-27T13:28:11.419324Z",
     "iopub.status.idle": "2024-02-27T13:28:11.432545Z",
     "shell.execute_reply": "2024-02-27T13:28:11.431739Z"
    },
    "executionInfo": {
     "elapsed": 6458,
     "status": "ok",
     "timestamp": 1709007851747,
     "user": {
      "displayName": "Ha Nguyen",
      "userId": "01126135657783667090"
     },
     "user_tz": -420
    },
    "id": "X5KDFfNizcZJ",
    "papermill": {
     "duration": 0.02419,
     "end_time": "2024-02-27T13:28:11.434374",
     "exception": false,
     "start_time": "2024-02-27T13:28:11.410184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_labels(path_in,path_out):\n",
    "    json_files = [file for file in os.listdir(path_in) if file.endswith('.json')]\n",
    "    \n",
    "    with open(os.path.join(path_in, json_files[0]), 'r') as f:\n",
    "        data = json.load(f)\n",
    "    df_images=pd.DataFrame(data['images'])\n",
    "    df_images.rename(columns={'id':'image_id'},inplace=True)\n",
    "    df_categories= pd.DataFrame(data['categories'])\n",
    "    df_categories.rename(columns={'id':'category_id'},inplace=True)\n",
    "    df_annotations=pd.DataFrame(data['annotations'])\n",
    "    merged_df = pd.merge(df_annotations, df_categories, how='left',left_on='category_id', right_on='category_id')\n",
    "    final_df = pd.merge(merged_df, df_images, how='left', left_on='image_id', right_on='image_id')\n",
    "    df=final_df[['category_id','bbox','file_name',]]\n",
    "    df[['bbox_x', 'bbox_y', 'bbox_width', 'bbox_height']] = pd.DataFrame(df['bbox'].apply(lambda x: pd.Series(x)))\n",
    "    df.drop('bbox', axis=1, inplace=True)\n",
    "    del df_images, df_categories, df_annotations, merged_df, final_df\n",
    "    \n",
    "    \n",
    "    os.mkdir(f\"/kaggle/working/yolov5/data/coco/labels/{path_out}\")\n",
    "    for file_name, group in df.groupby('file_name'):\n",
    "        # Tạo tên file label\n",
    "        file_name = file_name[:-3] + \"txt\"\n",
    "        label_filename = f\"/kaggle/working/yolov5/data/coco/labels/{path_out}/{file_name}\"\n",
    "\n",
    "        # Mở file label để ghi\n",
    "        with open(label_filename, 'w') as f:\n",
    "            # Lặp qua từng đối tượng trong ảnh\n",
    "            for index, row in group.iterrows():\n",
    "                # Ghi thông tin của mỗi đối tượng vào file label\n",
    "                class_index = row['category_id']\n",
    "                x_center = row['bbox_x'] \n",
    "                y_center = row['bbox_y'] \n",
    "                width = row['bbox_width']\n",
    "                height = row['bbox_height']\n",
    "\n",
    "                x_center /= 300\n",
    "                y_center /= 300\n",
    "                width /= 300\n",
    "                height /= 300\n",
    "\n",
    "                # Ghi thông tin vào file label\n",
    "                f.write(f\"{class_index} {x_center} {y_center} {width} {height}\\n\")\n",
    "    print('lable susses')\n",
    "    files = [file for file in os.listdir(path_in) if not file.endswith('.json')]\n",
    "    os.mkdir(f\"/kaggle/working/yolov5/data/coco/images/{path_out}\")\n",
    "\n",
    "    # Lặp qua từng tệp và sao chép vào thư mục đích\n",
    "    for file_name in files:\n",
    "        source_file = os.path.join(path_in, file_name)\n",
    "        destination_file = os.path.join(f'/kaggle/working/yolov5/data/coco/images/{path_out}', file_name)\n",
    "        shutil.copy2(source_file, destination_file)\n",
    "    print('image susses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b77d67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:28:11.451976Z",
     "iopub.status.busy": "2024-02-27T13:28:11.451245Z",
     "iopub.status.idle": "2024-02-27T13:33:34.796111Z",
     "shell.execute_reply": "2024-02-27T13:33:34.795169Z"
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1709008178922,
     "user": {
      "displayName": "Ha Nguyen",
      "userId": "01126135657783667090"
     },
     "user_tz": -420
    },
    "id": "GN2Ql6ivzjWp",
    "papermill": {
     "duration": 323.363602,
     "end_time": "2024-02-27T13:33:34.806027",
     "exception": false,
     "start_time": "2024-02-27T13:28:11.442425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable susses\n",
      "image susses\n",
      "lable susses\n",
      "image susses\n"
     ]
    }
   ],
   "source": [
    "# create_labels(test_path,'test')\n",
    "create_labels(train_path,'train')\n",
    "create_labels(valid_path,'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661eea28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:33:34.823591Z",
     "iopub.status.busy": "2024-02-27T13:33:34.823275Z",
     "iopub.status.idle": "2024-02-27T13:33:34.827092Z",
     "shell.execute_reply": "2024-02-27T13:33:34.826274Z"
    },
    "executionInfo": {
     "elapsed": 3750,
     "status": "ok",
     "timestamp": 1709008209870,
     "user": {
      "displayName": "Ha Nguyen",
      "userId": "01126135657783667090"
     },
     "user_tz": -420
    },
    "id": "Gt-znifu00rK",
    "outputId": "4ac09826-c2de-40da-cef5-39ba698d9e33",
    "papermill": {
     "duration": 0.014629,
     "end_time": "2024-02-27T13:33:34.828863",
     "exception": false,
     "start_time": "2024-02-27T13:33:34.814234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree(f'/kaggle/working/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397d2382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:33:34.846663Z",
     "iopub.status.busy": "2024-02-27T13:33:34.845917Z",
     "iopub.status.idle": "2024-02-27T13:33:34.860322Z",
     "shell.execute_reply": "2024-02-27T13:33:34.859339Z"
    },
    "id": "HbsPZd8z07c6",
    "papermill": {
     "duration": 0.02542,
     "end_time": "2024-02-27T13:33:34.862344",
     "exception": false,
     "start_time": "2024-02-27T13:33:34.836924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo tệp data.yaml thành công.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Đường dẫn của thư mục chứa tệp data.yaml\n",
    "folder_path = '/kaggle/working/yolov5/data/'\n",
    "\n",
    "# Nội dung của tệp data.yaml\n",
    "data_yaml_content = {\n",
    "    'train': '/kaggle/working/yolov5/data/coco/images/train',\n",
    "    'val': '/kaggle/working/yolov5/data/coco/images/valid',\n",
    "    'nc': 36,  # Số lượng lớp (number of classes)\n",
    "    'names': ['cars-bikes-people', 'Bus', 'Bushes', 'Person', 'Truck', 'backpack', 'bench',\n",
    "             'bicycle', 'boat', 'branch', 'car', 'chair', 'clock', 'crosswalk', 'door',\n",
    "             'elevator', 'fire_hydrant', 'green_light', 'gun', 'handbag', 'motorcycle',\n",
    "             'person', 'pothole', 'rat', 'red_light', 'scooter', 'sheep', 'stairs', 'stop_sign',\n",
    "             'suitcase', 'traffic light', 'traffic_cone', 'train', 'tree', 'truck', 'umbrella',\n",
    "              'yellow_light']  \n",
    "}\n",
    "\n",
    "# Ghi nội dung vào tệp data.yaml\n",
    "with open(folder_path + 'data.yaml', 'w') as file:\n",
    "    yaml.dump(data_yaml_content, file)\n",
    "\n",
    "print(\"Đã tạo tệp data.yaml thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e200d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T13:33:34.884955Z",
     "iopub.status.busy": "2024-02-27T13:33:34.884623Z",
     "iopub.status.idle": "2024-02-27T14:43:43.109590Z",
     "shell.execute_reply": "2024-02-27T14:43:43.108428Z"
    },
    "papermill": {
     "duration": 4208.240163,
     "end_time": "2024-02-27T14:43:43.112047",
     "exception": false,
     "start_time": "2024-02-27T13:33:34.871884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-27 13:33:45.351498: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-27 13:33:45.351631: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-27 13:33:45.536187: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1, batch_size=2, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\r\n",
      "WARNING ⚠️ invalid check_version(None, >=3.3) requested, please check values.\r\n",
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\r\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\r\n",
      "100%|███████████████████████████████████████| 14.1M/14.1M [00:00<00:00, 171MB/s]\r\n",
      "\r\n",
      "Overriding model.yaml nc=80 with nc=37\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    113274  models.yolo.Detect                      [37, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "Model summary: 214 layers, 7119418 parameters, 7119418 gradients, 16.3 GFLOPs\r\n",
      "\r\n",
      "Transferred 343/349 items from yolov5s.pt\r\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\r\n",
      "WARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\r\n",
      "See Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov5/data/coco/labels/train... 31944 images, 5\u001b[0m\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f105bec8d65461975_d20170228_m031540_c001_v0001038_t0052_png.rf.1c885a4840d731d2db0881d301007d43.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f105bec8d65461975_d20170228_m031540_c001_v0001038_t0052_png.rf.7e34f44abb0c9fb8eaba3a37c1d7554d.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f105bec8d65461975_d20170228_m031540_c001_v0001038_t0052_png.rf.cdc2d95b6ea15b7fc1d557c4553ecfa8.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f105bec8d65461bc2_d20170228_m031756_c001_v0001038_t0052_png.rf.7fe05952b0a9ab5cc99fff454e1f3c0d.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f105bec8d65461bc2_d20170228_m031756_c001_v0001038_t0052_png.rf.86e1fafb4a9822836cf13b5723dc2aca.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f105bec8d65461bc2_d20170228_m031756_c001_v0001038_t0052_png.rf.a2c7b0f26e5b4cab0484f6ebeaddf44a.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f21fd0_d20170225_m201447_c001_v0001038_t0018_png.rf.5a98b955c81f6ca3389dc533f9bf2b4b.jpg: 3 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f21fd0_d20170225_m201447_c001_v0001038_t0018_png.rf.743adbf14b8e4939f01181b5391dfa7e.jpg: 3 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f21fd0_d20170225_m201447_c001_v0001038_t0018_png.rf.cd63956c9ec3e3939591d5862ffccadd.jpg: 3 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f225f0_d20170225_m202204_c001_v0001038_t0018_png.rf.2b644e989deb728662aa7fc68e56a314.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f225f0_d20170225_m202204_c001_v0001038_t0018_png.rf.7ddab3945fe1e851c22dbeb65fe0de20.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f225f0_d20170225_m202204_c001_v0001038_t0018_png.rf.9c32b690cb4412e3c35b8efe701765dd.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.39dc29883e102028ae023c6cd7f9e2a5.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.9de47e3520ed2a834e1ac6f4bffd404b.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.c76d208ddff79978a7f04e0a23e07928.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.6466eb7ab1be84d88e7082542c6bea0f.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.8f0bdeece39c3d95e0a7acb44a431a91.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.c0cff6dcfb243298729ec2caa026d9d4.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f240ad_d20170225_m205340_c001_v0001038_t0018_png.rf.0e606bbb31d0bf78f4fda2404ff4597d.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f240ad_d20170225_m205340_c001_v0001038_t0018_png.rf.0f2a7154b4751ba8f071547f49219c23.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f240ad_d20170225_m205340_c001_v0001038_t0018_png.rf.a138c4b85b523fc57e5356786cb88632.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f24aff_d20170225_m210508_c001_v0001038_t0018_png.rf.132eb44e4b61cb198882bd8092f0dbc6.jpg: 3 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f24aff_d20170225_m210508_c001_v0001038_t0018_png.rf.76a053d534b1a1e104228033ec3bc59e.jpg: 3 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f24aff_d20170225_m210508_c001_v0001038_t0018_png.rf.df0de505453317afe9fc6d7c9c43bee2.jpg: 3 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f2501a_d20170225_m211031_c001_v0001038_t0018_png.rf.39db4ce107ab00adabd047fdee3e4326.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f2501a_d20170225_m211031_c001_v0001038_t0018_png.rf.6c42a59428c3ca0a53bec473f21dc2f0.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f2501a_d20170225_m211031_c001_v0001038_t0018_png.rf.a9a23236411d60862c84772e5797a69f.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f25f24_d20170225_m212728_c001_v0001038_t0018_png.rf.3bac0a90ba7d90fc2fdd5f0e7b80861e.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f25f24_d20170225_m212728_c001_v0001038_t0018_png.rf.721f91c7c17839df5cef9ab96136228e.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f109cae5016f25f24_d20170225_m212728_c001_v0001038_t0018_png.rf.a1be67c08e14967c468f7f49d78a7374.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac42f2c_d20170301_m020751_c001_v0001036_t0016_png.rf.45dce4896d4be96084fb028eb075cc60.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac42f2c_d20170301_m020751_c001_v0001036_t0016_png.rf.5d0b29cd53c1a3f63ed336334d1004bf.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac42f2c_d20170301_m020751_c001_v0001036_t0016_png.rf.885ff9bc58b9c80d1718ac08b42b2996.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac43054_d20170301_m021043_c001_v0001036_t0016_png.rf.3d7710cb4fec53f7bfbe3bd07f4537f5.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac43054_d20170301_m021043_c001_v0001036_t0016_png.rf.6dff8ceda74248d624a739e8882fcb4d.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac43054_d20170301_m021043_c001_v0001036_t0016_png.rf.c7a0af7e3f0918bb662e213a34ddc419.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac434e4_d20170301_m022204_c001_v0001036_t0016_png.rf.04eb84b9b028863d5e6393789f244279.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac434e4_d20170301_m022204_c001_v0001036_t0016_png.rf.21ebffdcee308af8757cfabc1fadd7af.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac434e4_d20170301_m022204_c001_v0001036_t0016_png.rf.624b243defbc5255adbb94e1270b2cf1.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac4368e_d20170301_m022629_c001_v0001036_t0016_png.rf.08951950bf2c41a1320fb5a5cbc6fc55.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac4368e_d20170301_m022629_c001_v0001036_t0016_png.rf.0deec8cd1f0fadc3aaed9830bebbb027.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/train/4_z8126b7d060d92d74599e0618_f110e5e48fac4368e_d20170301_m022629_c001_v0001036_t0016_png.rf.f74aebaa1e3e7cdd4b0c7408fe789288.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov5/data/coco/labels/train.cache\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (9.3GB ram): 100%|██████████| 32511/32511 [00:28<00:00, 11\u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov5/data/coco/labels/valid... 4189 images, 57 b\u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/valid/4_z8126b7d060d92d74599e0618_f105bec8d65461b60_d20170228_m031732_c001_v0001038_t0052_png.rf.3c6685fe5b0dcd84d33b5279a57cc699.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/valid/4_z8126b7d060d92d74599e0618_f105bec8d654623bd_d20170228_m032421_c001_v0001038_t0052_png.rf.280ab928fab2e9d377caa0f0a47f1246.jpg: 1 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/valid/4_z8126b7d060d92d74599e0618_f109cae5016f22c00_d20170225_m202920_c001_v0001038_t0018_png.rf.2acb28dd6793b4fc86c4b450d5af368a.jpg: 2 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/valid/4_z8126b7d060d92d74599e0618_f110e5e48fac43430_d20170301_m021957_c001_v0001036_t0016_png.rf.f142332b0b52178e88ac0761efd8c3d7.jpg: 4 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/yolov5/data/coco/images/valid/4_z8126b7d060d92d74599e0618_f110e5e48fac435e3_d20170301_m022435_c001_v0001036_t0016_png.rf.b7ada45bc2e094f414c33eb8de1ed5f4.jpg: 4 duplicate labels removed\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov5/data/coco/labels/valid.cache\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.2GB ram): 100%|██████████| 4246/4246 [00:03<00:00, 1253.6\u001b[0m\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.32 anchors/target, 0.995 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\r\n",
      "Plotting labels to runs/train/exp/labels.jpg... \r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "Image sizes 320 train, 320 val\r\n",
      "Using 2 dataloader workers\r\n",
      "Logging results to \u001b[1mruns/train/exp\u001b[0m\r\n",
      "Starting training for 1 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        0/0     0.432G    0.07475    0.02329    0.07466          1        320: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       4246       7242      0.319      0.259    0.00868    0.00291\r\n",
      "\r\n",
      "1 epochs completed in 1.130 hours.\r\n",
      "Optimizer stripped from runs/train/exp/weights/last.pt, 14.5MB\r\n",
      "Optimizer stripped from runs/train/exp/weights/best.pt, 14.5MB\r\n",
      "\r\n",
      "Validating runs/train/exp/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "Model summary: 157 layers, 7109914 parameters, 0 gradients, 16.1 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       4246       7242      0.319      0.259    0.00868    0.00291\r\n",
      "                   Bus       4246        275     0.0112      0.596     0.0235    0.00929\r\n",
      "                Bushes       4246        437    0.00749      0.359    0.00491    0.00227\r\n",
      "                Person       4246       1023     0.0058      0.117    0.00299   0.000888\r\n",
      "                 Truck       4246         45          0          0    0.00304    0.00114\r\n",
      "              backpack       4246          3          1          0          0          0\r\n",
      "                 bench       4246          3          1          0          0          0\r\n",
      "               bicycle       4246        358     0.0163      0.447     0.0216    0.00603\r\n",
      "                  boat       4246          4          1          0          0          0\r\n",
      "                branch       4246         62          0          0          0          0\r\n",
      "                   car       4246        463    0.00942      0.348    0.00945    0.00272\r\n",
      "                 chair       4246          1          1          0          0          0\r\n",
      "                 clock       4246          2          1          0          0          0\r\n",
      "             crosswalk       4246        354    0.00449      0.545    0.00524    0.00174\r\n",
      "                  door       4246        196    0.00535      0.694     0.0167    0.00555\r\n",
      "              elevator       4246        409     0.0101      0.548     0.0133    0.00428\r\n",
      "          fire_hydrant       4246        220     0.0112      0.605     0.0129     0.0048\r\n",
      "           green_light       4246        362    0.00937      0.387     0.0166    0.00484\r\n",
      "                   gun       4246        261    0.00913       0.36    0.00592    0.00258\r\n",
      "               handbag       4246          6          1          0          0          0\r\n",
      "            motorcycle       4246        238    0.00221     0.0126    0.00107   0.000248\r\n",
      "                person       4246         43    0.00188     0.0233    0.00113   0.000239\r\n",
      "               pothole       4246         95          1          0          0          0\r\n",
      "                   rat       4246        247    0.00355      0.121    0.00184   0.000738\r\n",
      "             red_light       4246        293     0.0053      0.614     0.0282    0.00821\r\n",
      "               scooter       4246        300    0.00633      0.287    0.00426    0.00177\r\n",
      "                stairs       4246         39          0          0   0.000523   0.000131\r\n",
      "             stop_sign       4246        213     0.0115      0.911     0.0306      0.013\r\n",
      "              suitcase       4246          5          1          0          0          0\r\n",
      "         traffic light       4246          8          1          0          0          0\r\n",
      "          traffic_cone       4246        544     0.0058      0.537     0.0159     0.0048\r\n",
      "                 train       4246        242      0.012      0.442    0.00908    0.00331\r\n",
      "                  tree       4246        275    0.00925      0.425     0.0075     0.0039\r\n",
      "                 truck       4246          3          1          0          0          0\r\n",
      "              umbrella       4246          2          1          0          0          0\r\n",
      "          yellow_light       4246        211     0.0132      0.697     0.0676     0.0194\r\n",
      "Results saved to \u001b[1mruns/train/exp\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 320 --batch 2 --epochs 1 --data data.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a150431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T14:43:46.093475Z",
     "iopub.status.busy": "2024-02-27T14:43:46.093029Z",
     "iopub.status.idle": "2024-02-27T14:43:55.902663Z",
     "shell.execute_reply": "2024-02-27T14:43:55.901554Z"
    },
    "papermill": {
     "duration": 11.273712,
     "end_time": "2024-02-27T14:43:55.905220",
     "exception": false,
     "start_time": "2024-02-27T14:43:44.631508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\r\n",
      "WARNING ⚠️ invalid check_version(None, >=3.3) requested, please check values.\r\n",
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "image 1/2 /kaggle/working/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 48.9ms\r\n",
      "image 2/2 /kaggle/working/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 55.9ms\r\n",
      "Speed: 0.5ms pre-process, 52.4ms inference, 236.0ms NMS per image at shape (1, 3, 640, 640)\r\n",
      "Results saved to \u001b[1mruns/detect/exp\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source data/images --weights yolov5s.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2f27520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T14:43:58.874529Z",
     "iopub.status.busy": "2024-02-27T14:43:58.873624Z",
     "iopub.status.idle": "2024-02-27T14:43:58.908416Z",
     "shell.execute_reply": "2024-02-27T14:43:58.907407Z"
    },
    "papermill": {
     "duration": 1.489908,
     "end_time": "2024-02-27T14:43:58.910578",
     "exception": false,
     "start_time": "2024-02-27T14:43:57.420670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã di chuyển ảnh vào thư mục output thành công.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "input_path = '/kaggle/input/Senior-Design-VIAD-4/test'\n",
    "output_path = '/kaggle/working/yolov5/data/images'\n",
    "\n",
    "image_filename = '-13AD8372-CDDB-4DCF-B8F9-DC10D210064B-png_jpg.rf.e8217e5555bb565dc324989173877f5a.jpg'\n",
    "source_image_path = os.path.join(input_path, image_filename)\n",
    "\n",
    "# Di chuyển ảnh từ thư mục input vào thư mục output\n",
    "destination_image_path = os.path.join(output_path, image_filename)\n",
    "shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "print(\"Đã di chuyển ảnh vào thư mục output thành công.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0ccaba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T14:44:01.948762Z",
     "iopub.status.busy": "2024-02-27T14:44:01.947941Z",
     "iopub.status.idle": "2024-02-27T14:44:11.718268Z",
     "shell.execute_reply": "2024-02-27T14:44:11.717102Z"
    },
    "papermill": {
     "duration": 11.295606,
     "end_time": "2024-02-27T14:44:11.720791",
     "exception": false,
     "start_time": "2024-02-27T14:44:00.425185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\r\n",
      "WARNING ⚠️ invalid check_version(None, >=3.3) requested, please check values.\r\n",
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "image 1/3 /kaggle/working/yolov5/data/images/-13AD8372-CDDB-4DCF-B8F9-DC10D210064B-png_jpg.rf.e8217e5555bb565dc324989173877f5a.jpg: 640x640 1 car, 12.0ms\r\n",
      "image 2/3 /kaggle/working/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 51.3ms\r\n",
      "image 3/3 /kaggle/working/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 50.3ms\r\n",
      "Speed: 0.5ms pre-process, 37.8ms inference, 145.5ms NMS per image at shape (1, 3, 640, 640)\r\n",
      "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source data/images --weights yolov5s.pt --conf 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f453c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T14:44:14.742897Z",
     "iopub.status.busy": "2024-02-27T14:44:14.741972Z",
     "iopub.status.idle": "2024-02-27T14:44:22.098324Z",
     "shell.execute_reply": "2024-02-27T14:44:22.097307Z"
    },
    "papermill": {
     "duration": 8.887667,
     "end_time": "2024-02-27T14:44:22.100705",
     "exception": false,
     "start_time": "2024-02-27T14:44:13.213038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: detect.py [-h] [--weights WEIGHTS [WEIGHTS ...]] [--source SOURCE]\r\n",
      "                 [--data DATA] [--imgsz IMGSZ [IMGSZ ...]]\r\n",
      "                 [--conf-thres CONF_THRES] [--iou-thres IOU_THRES]\r\n",
      "                 [--max-det MAX_DET] [--device DEVICE] [--view-img]\r\n",
      "                 [--save-txt] [--save-csv] [--save-conf] [--save-crop]\r\n",
      "                 [--nosave] [--classes CLASSES [CLASSES ...]] [--agnostic-nms]\r\n",
      "                 [--augment] [--visualize] [--update] [--project PROJECT]\r\n",
      "                 [--name NAME] [--exist-ok] [--line-thickness LINE_THICKNESS]\r\n",
      "                 [--hide-labels] [--hide-conf] [--half] [--dnn]\r\n",
      "                 [--vid-stride VID_STRIDE]\r\n",
      "detect.py: error: argument --source: expected one argument\r\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd839498",
   "metadata": {
    "papermill": {
     "duration": 1.492697,
     "end_time": "2024-02-27T14:44:25.127856",
     "exception": false,
     "start_time": "2024-02-27T14:44:23.635159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNNkKh6AzdD1vDLEYKc0/vR",
   "mount_file_id": "1PQnIfxlIk47y_CIG2sjoSR0bBfeItZxi",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4408472,
     "sourceId": 7572564,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4609.816337,
   "end_time": "2024-02-27T14:44:27.771763",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-27T13:27:37.955426",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
